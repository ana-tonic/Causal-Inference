{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "747b5f11-ad73-45b4-8789-f24fdd2a3587",
   "metadata": {},
   "source": [
    "<h1>1 Auxiliary Methods</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8f0223b-488b-4ea9-b209-713a201ea224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndarray_to_list(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, pd.Series):\n",
    "        return obj.tolist()\n",
    "    raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bcc2798-aa8c-4e1f-b9b0-ae8859d45e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time(func, *args, **kwargs):\n",
    "    \"\"\"Utility function to measure time taken by a function.\"\"\"\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    return result, end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e40eb7f-8038-484c-a907-c526dba9e2cb",
   "metadata": {},
   "source": [
    "<h1>2 Data Preparation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "162be744-0b9e-46be-a142-da443b09132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets for all possible combinations of control variables\n",
    "def create_all_Xs(df):\n",
    "    Xs = []\n",
    "    for column in df.columns:\n",
    "        X = df.drop(column, axis=1)\n",
    "        Xs.append(X)\n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6abc576c-7f02-418c-bba4-c9406a9ef6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method adds environment variables as controls\n",
    "# Data preparation\n",
    "def prepare_controls(df_energy, df_env):\n",
    "    \"\"\"\n",
    "    Prepares control variables for each combination of outcome and treatment.\n",
    "    \n",
    "    Args:\n",
    "        df_energy (DataFrame): DataFrame of treatment variables.\n",
    "        df_env (DataFrame): DataFrame of outcome variables.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Nested dictionary of control variables for each outcome and treatment.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare concatenated controls outside the loop\n",
    "    combined_controls = pd.concat([df_env, df_energy], axis=1)\n",
    "    \n",
    "    all_controls = {}\n",
    "    for outcome_name in df_env.columns:\n",
    "        controls_for_outcome = {}    \n",
    "        for (treatment_name, T) in df_energy.iteritems():\n",
    "            # Select only the columns that are not the current outcome or treatment\n",
    "            X = combined_controls.drop([outcome_name, treatment_name], axis=1, errors='ignore')\n",
    "            \n",
    "            # Check for duplicated column names\n",
    "            if X.columns.duplicated().any():\n",
    "                raise ValueError(f\"Duplicated column names detected when preparing controls for outcome {outcome_name} and treatment {treatment_name}.\")\n",
    "            \n",
    "            controls_for_outcome[treatment_name] = X\n",
    "        all_controls[outcome_name] = controls_for_outcome\n",
    "        \n",
    "    return all_controls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b011929-0dcf-4450-ad9d-fb3e14ff55dc",
   "metadata": {},
   "source": [
    "<h1>3 Model Training methods</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069cd34-719a-4c19-a0a2-c1e2efe58ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(Y, T, X, est_class, est_kwargs, verbose=False):\n",
    "    \"\"\"Train a single model and return it.\"\"\"\n",
    "    est_instance = est_class(**est_kwargs)\n",
    "    try:\n",
    "        # Check if the estimator class is DMLOrthoForest\n",
    "        if 'DMLOrthoForest' in str(est_class):\n",
    "            est_instance.fit(Y, T, X=X)\n",
    "        else:\n",
    "            est_instance.fit(Y, T, X=X, cache_values=True)\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error training model. Error: {e}\")\n",
    "        return None\n",
    "    return est_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46a640ab-1cc2-459f-a0a4-e60cc3413036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_causality(df_energy, df_env, est_class, est_kwargs={}, alpha=0.05, verbose=False):\n",
    "    \"\"\"\n",
    "    Trains a provided estimator on multiple treatments and outcomes, \n",
    "    recording effects and coefficients.\n",
    "    \n",
    "    Args:\n",
    "        df_energy (DataFrame): DataFrame of treatment variables.\n",
    "        df_env (DataFrame): DataFrame of outcome variables.\n",
    "        est_class (class): The class of the estimator to be instan tiated for causal inference.\n",
    "        est_kwargs (dict, optional): Keyword arguments to be passed to the estimator's constructor. Defaults to {}.\n",
    "        alpha (float, optional): The significance level for confidence intervals. Defaults to 0.05.\n",
    "        verbose (bool, optional): Whether to print progress updates. Defaults to False.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Nested dictionary of model estimators.\n",
    "    \"\"\"\n",
    "    \n",
    "    Xs = create_all_Xs(df_energy)\n",
    "    environmental_models = {}\n",
    "    \n",
    "    for (outcome_name, Y) in df_env.items():\n",
    "        if verbose: print(\"Outcome: \" + outcome_name)\n",
    "        fitted_models = {}\n",
    "        \n",
    "        for X, (treatment_name, T) in zip(Xs, df_energy.items()):\n",
    "            if verbose: print(\"\\tTreatment: \" + treatment_name)\n",
    "            \n",
    "            est_instance, training_time = measure_time(train_model, Y, T, X, est_class, est_kwargs, verbose)\n",
    "            \n",
    "            if est_instance is not None:\n",
    "                fitted_models[treatment_name] = est_instance\n",
    "                if verbose: print(f\"\\tTraining time: {training_time} seconds\")\n",
    "                \n",
    "        environmental_models[outcome_name] = fitted_models\n",
    "        \n",
    "    return environmental_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb087d-d7ec-4639-ba76-55b8c68848e0",
   "metadata": {},
   "source": [
    "<h1>4 Methods for persistence</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "352d5f2b-727e-4ef7-b826-bad989a21317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_estimators(env_models, dataset_dir_name, json_file_name, parent_dir_path='/home/nissatech/Documents/Double Machine Learning/Models'):\n",
    "    \"\"\"\n",
    "    Persist models and their metadata to disk.\n",
    "    \n",
    "    Parameters:\n",
    "    - env_models: Dictionary containing models.\n",
    "    - dataset_dir_name: Name of the dataset-specific directory.\n",
    "    - json_file_name: Name of the JSON file to save metadata.\n",
    "    - parent_dir_path: Path to the parent directory. Default is a hardcoded path.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_dir_path = os.path.join(parent_dir_path, dataset_dir_name)\n",
    "    json_file_path = os.path.join(dataset_dir_path, json_file_name)\n",
    "    models_dir_path = os.path.join(dataset_dir_path, \"models\")\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    for dir_path in [parent_dir_path, dataset_dir_path, models_dir_path]:\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "\n",
    "    # New dictionary to store model paths\n",
    "    model_paths_dict = {}\n",
    "\n",
    "    # Replace LinearDML objects with paths and save the models\n",
    "    for key, value in env_models.items():\n",
    "        model_paths_dict[key] = {}\n",
    "        if isinstance(value, dict):\n",
    "            for subkey, subvalue in value.items():\n",
    "                if isinstance(subvalue, econml.dml.dml.LinearDML):\n",
    "                    model_path = os.path.join(models_dir_path, f\"{key}_{subkey}.pkl\")\n",
    "                    joblib.dump(subvalue, model_path)\n",
    "                    model_paths_dict[key][subkey] = model_path\n",
    "\n",
    "    # Serialize the dictionary to JSON\n",
    "    with open(json_file_path, 'w') as f:\n",
    "        json.dump(model_paths_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5844efb-bf96-45d1-b07e-c6f6c8318b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_estimators(path):\n",
    "    \"\"\"\n",
    "    Load the estimators from the paths saved in the JSON file.\n",
    "    \n",
    "    Args:\n",
    "    - path (str): Path to the JSON file where the dictionary with estimator paths is saved.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary with the same structure as the original, but with LinearDML objects loaded from disk.\n",
    "    \"\"\"\n",
    "    # Load the dictionary from the JSON file\n",
    "    with open(path, 'r') as f:\n",
    "        env_models = json.load(f)\n",
    "    \n",
    "    # Iterate over the dictionary to load the LinearDML objects\n",
    "    for outer_key, inner_dict in env_models.items():\n",
    "        for inner_key, value in inner_dict.items():\n",
    "            if isinstance(value, str) and value.endswith('.pkl'):\n",
    "                # If the value is a path to a .pkl file, load the LinearDML object from this path\n",
    "                model = joblib.load(value)\n",
    "                # Replace the path with the loaded LinearDML object\n",
    "                inner_dict[inner_key] = model\n",
    "    \n",
    "    return env_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926b5053-48d7-415d-a48e-fabb36d4bf98",
   "metadata": {},
   "source": [
    "<h1>5 Visualisation methods</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83185651-7ceb-4716-b0fc-23d48fa37575",
   "metadata": {},
   "source": [
    "<h2>5.1 Treatment vs Outcome</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd15a4-a9e6-434e-ba7d-88cddc46eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_all_treatments_vs_all_outcomes(df_treatments, df_outcomes):\n",
    "    for outcome_label, outcome_values in df_outcomes.items():\n",
    "        for treatment_label, treatment_values in df_treatments.items():\n",
    "            scatter_treatment_vs_outcome(treatment_values, outcome_values, treatment_label, outcome_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08d8ae01-32e7-4071-8dc9-9d3ab1e003ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_all_treatments_vs_single_outcome(df_treatments, outcome_values, outcome_label):\n",
    "    for treatment_label, treatment_values in df_treatments.items():\n",
    "        scatter_treatment_vs_outcome(treatment_values, outcome_values, treatment_label, outcome_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3940881e-82e0-4869-af7e-66b7f589567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_treatment_vs_outcome(treatment_values, outcome_values, treatment_label, outcome_label):\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))  # Optional: Set the figure size\n",
    "    plt.scatter(treatment_values, outcome_values, alpha=0.5)\n",
    "    \n",
    "    plt.title(\"Treatment: \" + treatment_label + \" vs Outcome: \" + outcome_label)\n",
    "    plt.xlabel(treatment_label)\n",
    "    plt.ylabel(outcome_label)\n",
    "    \n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188f800-4349-48c0-b58b-f6495b6b383b",
   "metadata": {},
   "source": [
    "<h2>5.2 CATE value</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31a336fa-de81-4394-a775-88c02a872c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_models(environmental_models):\n",
    "    \n",
    "    for env_parameter_name, env_models in environmental_models.items():\n",
    "        for energy_parameter_name, model in env_models.items():\n",
    "    \n",
    "            # Create a histogram of the CATE estimates - Conditional Average Treatment Effect\n",
    "            fig = go.Figure(data=[go.Histogram(x=model['pnt_effect'], nbinsx=30)])\n",
    "            \n",
    "            fig.update_layout(\n",
    "                title_text='Distribution of Estimated CATE for Feature: {}, Outcome: {}'.format(energy_parameter_name, env_parameter_name), \n",
    "                xaxis_title_text='Estimated CATE', \n",
    "                yaxis_title_text='Frequency', \n",
    "            )\n",
    "            \n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93db555e-a7af-48e0-b391-c7bde16c6181",
   "metadata": {},
   "source": [
    "<h2>5.3 Visualize MSE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e86f055-2a91-476a-92a8-4ae383e970cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mse(model_type, models_dict, title_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Visualizes the Mean Squared Error (MSE) for each model based on their residuals.\n",
    "\n",
    "    Args:\n",
    "    - models_dict (dict): Dictionary where the key is the model name, and the value is the model with a `residuals_` attribute.\n",
    "    - title_prefix (str): Prefix to be added to the chart title.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    if(model_type == 'outcome'):\n",
    "        num = 0 \n",
    "    elif(model_type == 'treatment'):\n",
    "        num = 1\n",
    "    \n",
    "    # Calculate MSE for each model\n",
    "    mse_values = [np.mean(model.residuals_[num]**2) for model in models_dict.values()]\n",
    "    model_names = list(models_dict.keys())\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(model_names, mse_values, color='skyblue')\n",
    "    plt.ylabel('Mean Squared Error (MSE)')\n",
    "    plt.title(f'Mean Squared Error for Each Model ({title_prefix})')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c02b7a-c08c-4820-ad4f-96864d3b1bf2",
   "metadata": {},
   "source": [
    "<h2>5.4 True vs Predicted</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c89915b-b8e4-4e28-8df3-91be2d9842ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_vs_predicted_treatment_model(df_energy, env_models, outcome_label):\n",
    "    for energy_parameter_name, model in env_models.items():\n",
    "        T = df_energy[energy_parameter_name]\n",
    "        predicted_T = T + model.residuals_[1]\n",
    "        visualize_True_vs_Predicted('treatment', T, predicted_T, energy_parameter_name, outcome_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc3ec322-1462-4333-a2c3-5d0c5bb4f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_vs_predicted_outcome_model(df_env, env_models, outcome_label):\n",
    "    Y = df_env[outcome_label]\n",
    "    for energy_parameter_name, model in env_models.items():\n",
    "        predicted_y = Y + model.residuals_[0]\n",
    "        visualize_True_vs_Predicted('output', Y, predicted_y, energy_parameter_name, outcome_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d451383-b5e7-40f4-9d8c-1e3bd2056a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_true_vs_predicted(model_type, true_values, pred_values, treatment_label, outcome_label):\n",
    "    \"\"\"\n",
    "    Visualize the true values against the predicted values for regression models.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_type (str): Type of the model, either 'outcome' or 'treatment'.\n",
    "    - true_values (array-like): The true values of the variable.\n",
    "    - pred_values (array-like): The predicted values of the variable.\n",
    "    - treatment_label (str): The label for the treatment variable.\n",
    "    - outcome_label (str): The label for the outcome variable.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.title(f\"Treatment: {treatment_label}, Outcome: {outcome_label}\")\n",
    "    \n",
    "    if model_type == 'outcome':\n",
    "        xlabel = outcome_label\n",
    "        ylabel = \"Predicted \" + outcome_label\n",
    "    elif model_type == 'treatment':\n",
    "        xlabel = treatment_label\n",
    "        ylabel = \"Predicted \" + treatment_label\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be either 'outcome' or 'treatment'\")\n",
    "    \n",
    "    plt.xlabel(f\"True {xlabel}\")\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    plt.scatter(true_values, pred_values, alpha=0.5)\n",
    "    plt.plot([min(true_values), max(true_values)], [min(true_values), max(true_values)], 'r--')  # 45-degree line\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e6ae6b-29b6-4d34-bd14-156416779a84",
   "metadata": {},
   "source": [
    "<h2>5.5 Actual and Predicted values through Time</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84f9d812-b490-41d0-ad9d-fec019230076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_and_predicted_vs_time_treatment_model(df_energy, env_models, outcome_label):\n",
    "    for energy_parameter_name, model in env_models.items():\n",
    "        T = df_energy[energy_parameter_name]\n",
    "        predicted_T = T + model.residuals_[1]\n",
    "        visualize_true_and_pred_vs_time('treatment', T, predicted_T, energy_parameter_name, outcome_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db2e0c5d-bec5-4f37-8710-1d0af1dc7380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_and_predicted_vs_time_outcome_model(df_env, env_models, outcome_label):\n",
    "    Y = df_env[outcome_label]\n",
    "    for energy_parameter_name, model in env_models.items():\n",
    "        predicted_y = Y + model.residuals_[0]\n",
    "        visualize_true_and_pred_vs_time('outcome', Y, predicted_y, energy_parameter_name, outcome_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60124261-685b-485e-9cc2-bccaa723c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_true_and_pred_vs_time(model_type, true_values, pred_values, treatment_label, outcome_label):\n",
    "    \"\"\"\n",
    "    Visualize the time series of true and predicted values on the same plot.\n",
    "    \n",
    "    Parameters:\n",
    "    - true_values (pandas.Series or list): A series or list containing the true values over time.\n",
    "    - pred_values (pandas.Series or list): A series or list containing the predicted values over time.\n",
    "    - label (str): A label for the data being visualized, used in the plot title.\n",
    "    \n",
    "    Returns:\n",
    "    - None: This function displays a plot.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "    \n",
    "    # Graph for predicted values\n",
    "    ax.plot(pred_values, color='salmon', linestyle='--', label='Predicted values', linewidth=2)\n",
    "    \n",
    "    # Graph for true values\n",
    "    ax.plot(true_values, color='royalblue', label='True Values', linewidth=2)\n",
    "    \n",
    "    if(model_type == 'outcome'):\n",
    "        ax.set_title(\"Time Series of True and Predicted \" + outcome_label + \", treatment is \" + treatment_label)\n",
    "    elif(model_type == 'treatment'):\n",
    "        ax.set_title(\"Time Series of True and Predicted \" + treatment_label + \", outcome is \" + outcome_label)\n",
    "    \n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f97ce-bb32-4b21-8b79-012c02846cac",
   "metadata": {},
   "source": [
    "<h2>5.6 Plot Residuals</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebc57d78-99b3-475a-8cae-976ab3cc03f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(estimators):\n",
    "    \n",
    "    for env_parameter_name, env_models in estimators.items():\n",
    "        for energy_parameter_name, model in env_models.items():\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.scatter(model.residuals_[1], model.residuals_[0], alpha=0.5)\n",
    "            plt.xlabel(f'Residual Treatment for {energy_parameter_name}')\n",
    "            plt.ylabel(f'Residual Outcome for {env_parameter_name}')\n",
    "            plt.title(f'Residuals from DML: {env_parameter_name} vs. {energy_parameter_name}')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002dad0-70a1-44ba-a6de-bb7a0443001d",
   "metadata": {},
   "source": [
    "<h2>5.7 Second Stage Prediction</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1957ca2-acd4-4e94-a4de-8b856e7b19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predicted_vs_actual(model, X, T, Y, df_energy_3, outcome_name, treatment_label):\n",
    "    \"\"\"\n",
    "    Visualize the predicted vs actual energy consumption.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The trained model.\n",
    "    - X: The features.\n",
    "    - T: The treatment variable.\n",
    "    - Y: The actual outcome values.\n",
    "    - df_energy_3: DataFrame containing the energy data with a datetime index.\n",
    "    \n",
    "    Returns:\n",
    "    - mae: Mean Absolute Error between the predicted and actual values.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Predict the causal effect for the test set\n",
    "    causal_effects = model.effect(X)\n",
    "\n",
    "    # Adjust the features for computing residuals\n",
    "    X_train_combined = pd.concat([T, X], axis=1)\n",
    "\n",
    "    # Predict the outcome based on the causal effect\n",
    "    predicted_consumption = Y - np.mean(model.residuals_[0]) + causal_effects\n",
    "\n",
    "    # Convert predicted_consumption to a 1D array if it's not\n",
    "    if hasattr(predicted_consumption, 'values'):\n",
    "        predicted_consumption = predicted_consumption.values.ravel()\n",
    "    else:\n",
    "        predicted_consumption = np.array(predicted_consumption).ravel()\n",
    "\n",
    "    # Convert Y to a 1D array if it's not\n",
    "    if hasattr(Y, 'values'):\n",
    "        Y_values = Y.values.ravel()\n",
    "    else:\n",
    "        Y_values = np.array(Y).ravel()\n",
    "\n",
    "    mae = mean_absolute_error(Y_values, predicted_consumption)\n",
    "    print(f\"Mean Absolute Error on Test Set: {mae:.2f}\")\n",
    "\n",
    "    # Convert df_energy_3.index to a 1D array if it's not\n",
    "    if hasattr(df_energy_3.index, 'values'):\n",
    "        index_values = df_energy_3.index.values.ravel()\n",
    "    else:\n",
    "        index_values = np.array(df_energy_3.index).ravel()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(index_values, predicted_consumption, label=\"Predicted Effect of\", color='red', linestyle='--')\n",
    "    plt.plot(index_values, Y_values, label=\"Actual Effect\", color='blue', linewidth=2)\n",
    "    plt.title(\"Predicted Effect of: \" + treatment_label + \" on: \" + outcome_name)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Effect\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151fec35-a4f3-4273-8e6f-01fbdbffd299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predicted_vs_actual_for_env(outcome_label, env_models, df_energy, df_env):\n",
    "    Y = df_env[outcome_label]\n",
    "    \n",
    "    for energy_parameter_name, model in env_models.items():\n",
    "        X = df_energy.drop(energy_parameter_name, axis=1)\n",
    "        T = df_energy[energy_parameter_name]\n",
    "        visualize_predicted_vs_actual(model, X, T, Y, df_energy_3_normalized, outcome_label, energy_parameter_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
